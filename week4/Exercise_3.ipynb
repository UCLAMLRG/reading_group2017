{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.loadtxt('input_ex3.dat')\n",
    "\n",
    "label=['ID','SS-IN','SED-IN','COND-IN','SS-OUT','SED-OUT','COND-OUT','STAT']\n",
    "out=['OK','set','sol']\n",
    "nout=3\n",
    "nfeatures=len(label)-2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct a proper Naives model, we need the prior of the target levels, i.e. $P\\Big[t_j\\Big]$ and the conditional probability of the features given the target levels $P\\Big[f_i~|~t_j\\Big]$. First, lets compte the priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30769231  0.38461538  0.30769231]\n"
     ]
    }
   ],
   "source": [
    "priors = np.zeros(nout)\n",
    "\n",
    "for i in range(len(priors)):\n",
    "    priors[i] =  dat[:,-1].tolist().count(i+1)\n",
    "    \n",
    "priors /=np.sum(priors)\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us compute the conditional pdf. Following the exercice, we will assume that all $P\\Big[f_i~|~t_j\\Big]$ are normally distributed. We thus have to determine $N_{features}\\times N_{target}$ mean and standard deviations that characterized these pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(SS-IN|OK  = N(m=189.0,sig=39.3319208786)\n",
      "P(SED-IN|OK  = N(m=3.125,sig=0.216506350946)\n",
      "P(COND-IN|OK  = N(m=1860.5,sig=321.64382475)\n",
      "P(SS-OUT|OK  = N(m=18.0,sig=5.24404424085)\n",
      "P(SED-OUT|OK  = N(m=0.054,sig=0.0843534231671)\n",
      "P(COND-OUT|OK  = N(m=2036.0,sig=460.890984941)\n",
      "P(SS-IN|set  = N(m=200.8,sig=49.30882274)\n",
      "P(SED-IN|set  = N(m=4.4,sig=1.59373774505)\n",
      "P(COND-IN|set  = N(m=1251.2,sig=103.971919286)\n",
      "P(SS-OUT|set  = N(m=98.0,sig=20.9093280619)\n",
      "P(SED-OUT|set  = N(m=1.018,sig=1.3654654884)\n",
      "P(COND-OUT|set  = N(m=1372.0,sig=127.525683688)\n",
      "P(SS-IN|sol  = N(m=1301.0,sig=420.403377722)\n",
      "P(SED-IN|sol  = N(m=32.5,sig=10.3561575886)\n",
      "P(COND-IN|sol  = N(m=1621.0,sig=392.342325017)\n",
      "P(SS-OUT|sol  = N(m=49.1,sig=32.6975534253)\n",
      "P(SED-OUT|sol  = N(m=1293.0,sig=373.214415584)\n",
      "P(COND-OUT|sol  = N(m=832.85,sig=829.922738874)\n",
      "[[  1.89000000e+02   3.12500000e+00   1.86050000e+03   1.80000000e+01\n",
      "    5.40000000e-02   2.03600000e+03]\n",
      " [  2.00800000e+02   4.40000000e+00   1.25120000e+03   9.80000000e+01\n",
      "    1.01800000e+00   1.37200000e+03]\n",
      " [  1.30100000e+03   3.25000000e+01   1.62100000e+03   4.91000000e+01\n",
      "    1.29300000e+03   8.32850000e+02]]\n",
      "[[  3.93319209e+01   2.16506351e-01   3.21643825e+02   5.24404424e+00\n",
      "    8.43534232e-02   4.60890985e+02]\n",
      " [  4.93088227e+01   1.59373775e+00   1.03971919e+02   2.09093281e+01\n",
      "    1.36546549e+00   1.27525684e+02]\n",
      " [  4.20403378e+02   1.03561576e+01   3.92342325e+02   3.26975534e+01\n",
      "    3.73214416e+02   8.29922739e+02]]\n"
     ]
    }
   ],
   "source": [
    "mean = np.zeros((nout,nfeatures))\n",
    "std  = np.zeros((nout,nfeatures))\n",
    "\n",
    "for j in range(nout):\n",
    "    idx = np.where(dat[:,-1]==j+1)\n",
    "    for i in range(nfeatures):\n",
    "        mean[j,i] = np.mean(dat[idx,i+1])\n",
    "        std[j,i]  = np.std(dat[idx,i+1])\n",
    "        print('P('+label[i+1]+'|'+out[j]+'  = N(m='+str(mean[j,i])+',sig='+str(std[j,i])+')')\n",
    "print (mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been built (youpie) and we can now make predictions out of it. Our purpose is to determine what is the status of the water treatment given some features. For this, we use the Naives Bayes Model. We introduce the ``Model'' of a target given some features: $M\\Big[t_j ~| ~ \\mathbf f\\Big]=\\prod_{i=1}^{N_{features}}P\\Big[f_i ~|~t_j\\Big]P[t_j]$ (with $\\mathbf f$ a set of features). This $M\\Big[t_j ~| ~ \\mathbf f\\Big]\\propto P\\Big[t_j ~| ~ \\mathbf f\\Big]$ up to a constant that does not depend on the target levels (and under the assumption of conditional independence). The Naive Bayes model prediction is given by the target level which gives the maximal $M\\Big[t_j ~| ~ \\mathbf f\\Big]$ (MAP estimator).\n",
    "\n",
    "In conclusion, given a set of features $\\mathbf f$, we need to compute $M\\Big[t_j ~| ~ \\mathbf f\\Big]$ for the 3 target levels and choose the one which is maximal.\n",
    "In the exercice 3, the set of features observed is given by\n",
    "- SS-IN    = 222\n",
    "- SED-IN   = 4.5\n",
    "- COND-IN  = 1518\n",
    "- SS-OUT   = 74\n",
    "- SED-OUT  = 0.25\n",
    "- COND-OUT = 1642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 222.0 189.0 39.3319208786 0.00713354825875\n",
      "0 1 4.5 3.125 0.216506350946 3.21489929727e-09\n",
      "0 2 1518.0 1860.5 321.64382475 0.000703580641306\n",
      "0 3 74.0 18.0 5.24404424085 1.31389901518e-26\n",
      "0 4 0.25 0.054 0.0843534231671 0.318014731127\n",
      "0 5 1642.0 2036.0 460.890984941 0.000600650122819\n",
      "1 0 222.0 200.8 49.30882274 0.0073764174633\n",
      "1 1 4.5 4.4 1.59373774505 0.249826381181\n",
      "1 2 1518.0 1251.2 103.971919286 0.000142604400687\n",
      "1 3 74.0 98.0 20.9093280619 0.00987379173825\n",
      "1 4 0.25 1.018 1.3654654884 0.249422651894\n",
      "1 5 1642.0 1372.0 127.525683688 0.000332600736284\n",
      "2 0 222.0 1301.0 420.403377722 3.52224687167e-05\n",
      "2 1 4.5 32.5 10.3561575886 0.000996230932694\n",
      "2 2 1518.0 1621.0 392.342325017 0.000982379194148\n",
      "2 3 74.0 49.1 32.6975534253 0.00912991540072\n",
      "2 4 0.25 1293.0 373.214415584 2.65215299121e-06\n",
      "2 5 1642.0 832.85 829.922738874 0.000298854220172\n",
      "[  1.24604662e-44   8.27916286e-14   7.67538782e-23]\n",
      "[  1.50503939e-31   9.99999999e-01   9.27072935e-10]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([222,4.5,1518,74,0.25,1642])\n",
    "M = priors.copy()\n",
    "\n",
    "for j in range(nout):\n",
    "    for i in range(nfeatures):\n",
    "        print(j,i,x[i],mean[j,i],std[j,i],norm.pdf(x[i],mean[j,i],std[j,i]))\n",
    "        M[j] *= norm.pdf(x[i],mean[j,i],std[j,i])\n",
    "\n",
    "print(M)\n",
    "print(M/np.sum(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
